<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>记一次 Julia 代码性能优化过程 - Ionizing Radiation</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="Ionizing"><meta name=description content=" 运行环境 优化过程  原始版本 使用 C-ffi 的 rgamma 与 rnorm 去除外部依赖 内存分配情况分析 去除内层循环的内存分配 去除外层循环的内存分配 使用多线程加速   总结  这是和某三爷讨论后对交流内容的整理。
"><meta name=keywords content="PhysicalChemistry,ComputerScience"><meta name=generator content="Hugo 0.82.0"><link rel=canonical href=http://ionizing.page/post/a-try-on-julia-code-optimization/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.f7440b5c0d223f47a09bf5853465434e6f91d80a591c2f8d2d5e8220e5db0580.css integrity="sha256-90QLXA0iP0egm/WFNGVDTm+R2ApZHC+NLV6CIOXbBYA=" media=screen crossorigin=anonymous><meta property="og:title" content="记一次 Julia 代码性能优化过程"><meta property="og:description" content="


运行环境
优化过程

原始版本
使用 C-ffi 的 rgamma 与 rnorm
去除外部依赖
内存分配情况分析
去除内层循环的内存分配
去除外层循环的内存分配
使用多线程加速


总结


这是和某三爷讨论后对交流内容的整理。"><meta property="og:type" content="article"><meta property="og:url" content="http://ionizing.page/post/a-try-on-julia-code-optimization/"><meta property="article:section" content="post"><meta property="article:published_time" content="2021-04-16T13:06:00+08:00"><meta property="article:modified_time" content="2021-04-16T13:06:00+08:00"><meta itemprop=name content="记一次 Julia 代码性能优化过程"><meta itemprop=description content="


运行环境
优化过程

原始版本
使用 C-ffi 的 rgamma 与 rnorm
去除外部依赖
内存分配情况分析
去除内层循环的内存分配
去除外层循环的内存分配
使用多线程加速


总结


这是和某三爷讨论后对交流内容的整理。"><meta itemprop=datePublished content="2021-04-16T13:06:00+08:00"><meta itemprop=dateModified content="2021-04-16T13:06:00+08:00"><meta itemprop=wordCount content="3575"><meta itemprop=keywords content="Posts,Julia,Optimization,ParallelProgramming,"><meta name=twitter:card content="summary"><meta name=twitter:title content="记一次 Julia 代码性能优化过程"><meta name=twitter:description content="


运行环境
优化过程

原始版本
使用 C-ffi 的 rgamma 与 rnorm
去除外部依赖
内存分配情况分析
去除内层循环的内存分配
去除外层循环的内存分配
使用多线程加速


总结


这是和某三爷讨论后对交流内容的整理。"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>IonizingRadiation</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=http://ionizing.page/>Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://ionizing.page/post/>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://ionizing.page/tags/>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://ionizing.page/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://ionizing.page/about/>About</a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>IonizingRadiation</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=http://ionizing.page/>Home</a></li><li class=menu-item><a class=menu-item-link href=http://ionizing.page/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=http://ionizing.page/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=http://ionizing.page/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=http://ionizing.page/about/>About</a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>记一次 Julia 代码性能优化过程</h1><div class=post-meta><time datetime=2021-04-16 class=post-time>2021-04-16</time><div class=post-category><a href=http://ionizing.page/categories/programming/>Programming</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#运行环境>运行环境</a></li><li><a href=#优化过程>优化过程</a><ul><li><a href=#原始版本>原始版本</a></li><li><a href=#使用-c-ffi-的-rgamma-与-rnorm>使用 C-ffi 的 <code>rgamma</code> 与 <code>rnorm</code></a></li><li><a href=#去除外部依赖>去除外部依赖</a></li><li><a href=#内存分配情况分析>内存分配情况分析</a></li><li><a href=#去除内层循环的内存分配>去除内层循环的内存分配</a></li><li><a href=#去除外层循环的内存分配>去除外层循环的内存分配</a></li><li><a href=#使用多线程加速>使用多线程加速</a></li></ul></li><li><a href=#总结>总结</a></li></ul></nav></div></div><div class=post-content><ul><li><a href=#%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83>运行环境</a></li><li><a href=#%E4%BC%98%E5%8C%96%E8%BF%87%E7%A8%8B>优化过程</a><ul><li><a href=#%E5%8E%9F%E5%A7%8B%E7%89%88%E6%9C%AC>原始版本</a></li><li><a href=#%E4%BD%BF%E7%94%A8-c-ffi-%E7%9A%84-rgamma-%E4%B8%8E-rnorm>使用 C-ffi 的 <code>rgamma</code> 与 <code>rnorm</code></a></li><li><a href=#%E5%8E%BB%E9%99%A4%E5%A4%96%E9%83%A8%E4%BE%9D%E8%B5%96>去除外部依赖</a></li><li><a href=#%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%83%85%E5%86%B5%E5%88%86%E6%9E%90>内存分配情况分析</a></li><li><a href=#%E5%8E%BB%E9%99%A4%E5%86%85%E5%B1%82%E5%BE%AA%E7%8E%AF%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D>去除内层循环的内存分配</a></li><li><a href=#%E5%8E%BB%E9%99%A4%E5%A4%96%E5%B1%82%E5%BE%AA%E7%8E%AF%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D>去除外层循环的内存分配</a></li><li><a href=#%E4%BD%BF%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%8A%A0%E9%80%9F>使用多线程加速</a></li></ul></li><li><a href=#%E6%80%BB%E7%BB%93>总结</a></li></ul><p>这是和某三爷讨论后对交流内容的整理。</p><p>众所周知， Julia 是一种高级通用动态编程语言，它专为科学计算而生。为了方便科研人员使用，它的语法被设计得很像 MATLAB ，但比 MATLAB 更合理（譬如数组引用使用 <code>[]</code>
，而不是 <code>()</code> ）。作为一门很年轻的语言，它吸收了前辈们的很多优点，也有着自己的特色，但最受人青睐的一点在于：尽管它是一门动态语言，却宣称拥有 C/C++ 一般的性能。
一般而言，动态语言的表现能力更为出色，能用更少的代码做更多的事，开发效率高；而静态语言的编译器后端更容易优化，运行效率高。Julia 有动态性，开发效率毋庸置疑，一些测评也显示 Julia 确实拥有很强的性能，但这是否意味着你随手写的一段代码就能有很高并且达到预期的性能？我看未必。</p><h2 id=运行环境>运行环境</h2><table><thead><tr><th>Processor</th><th>Intel Core i5 9600KF</th></tr></thead><tbody><tr><td>Memory</td><td>16GB 3200MHz</td></tr><tr><td>OS</td><td>macOS 10.15.6</td></tr><tr><td>Julia</td><td>1.5.1</td></tr></tbody></table><h2 id=优化过程>优化过程</h2><h3 id=原始版本>原始版本<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></h3><p>废话不多说，直接开始正题，先来看今天的主角<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>using Rmath;
using BenchmarkTools;

function JGibbs1(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    for i = 1:N
        for j = 1:thin
            x = rgamma(1, 3, 1/(y*y + 4))[1]
            y = rnorm(1, 1/(x+1), 1/sqrt(2(x + 1)))[1]
        end
        mat[i,:] = [x,y]
    end
    mat
end;

@btime JGibbs1(20000, 200);
</code></pre></td></tr></table></div></div><p>这是一段关于 Gibbs 采样的代码，它主要由两个循环组成，外部循环一次产生两个值，内部循环是迭代式的，即下一次循环要用到上次循环的结果。很明显它引入了 R 的库，并用
R 的 <code>rgamma</code> 和 <code>rnorm</code> 实现，那么它的性能是怎样的呢？</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>  501.798 ms (8020002 allocations: 734.56 MiB)
</code></pre></td></tr></table></div></div><p>根据原文的说法，它的性能已经比 <code>Rgibbs</code> 快 17 倍，比 <code>RCgibbs</code> 快 13 倍，已经是比较令人满意的结果了。</p><h3 id=使用-c-ffi-的-rgamma-与-rnorm>使用 C-ffi 的 <code>rgamma</code> 与 <code>rnorm</code><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></h3><p>由于直接用 R 写的代码可能并不是最快的，而且它还在内层循环里，所以我们有理由相信使用 C-ffi<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> 版的 <code>rgamma</code> 与 <code>rnorm</code> 会更快。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>using Rmath
import Rmath: libRmath
using BenchmarkTools
function JGibbs2(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    for i = 1:N
        for j = 1:thin
            x = ccall((:rgamma, libRmath), Float64, (Float64, Float64), 3., 1/(y*y + 4))
            y = ccall((:rnorm, libRmath), Float64, (Float64, Float64), 1/(x+1), 1/sqrt(2*(x + 1)))
        end
        mat[i,:] = [x,y]
    end
    mat
end

@btime JGibbs2(20000, 200);
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>JGibbs2 (generic function with 1 method)
  259.387 ms (20002 allocations: 2.14 MiB)
</code></pre></td></tr></table></div></div><p>果然，使用 C-ffi 版的函数后性能又提升了一倍！</p><h3 id=去除外部依赖>去除外部依赖<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></h3><p>尽管使用 C 的实现后， <code>JGibbs</code> 性能提升巨大，但依赖外部库多少有点让人感觉不爽，
毕竟它和 Julia 所宣称的高性能关系不是很大（核心部分是 C 的贡献，而不是 Julia）。
既然 Julia 也是高性能语言，何不拿纯 Julia 写一个 <code>JGibbs</code> 来比比？</p><p>Julia 是为科学计算而生，它的社区维护了一个统计学库 <code>Distributions</code> ，里面包含了
<code>gamma</code> 与 <code>norm</code> 分布的函数，可以用来替换 <code>rgamma</code> 和 <code>rnorm</code> ，写完之后是这个样子：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>using BenchmarkTools;
using Distributions;

function JGibbs3(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    for i = 1:N
        for j = 1:thin
            x = rand(Gamma(3, 1/(y^2 + 4)), 1)[1]
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))), 1)[1]
        end
        mat[i,:] = [x,y]
    end
    mat
end

@btime JGibbs3(20000, 200);
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>JGibbs3 (generic function with 1 method)
  550.624 ms (8020002 allocations: 734.56 MiB)
</code></pre></td></tr></table></div></div><p>咦？看起来它还没有使用 R-ffi 的函数快！</p><p>那么问题出在哪呢？仔细看结果，除了时间之外还有两个数据，一个是执行一次该函数时所分配内存的次数，另一个是函数执行期间分配内存的总量。我们回头看一下使用 C-ffi 的版本，它的测试结果显示除了性能更强外，内存分配的次数和总量也更少！而且 8020002
恰好是 20002 的 400 倍左右，正好是 <code>thin=200</code> 的 2 倍。据此，我们可以猜想，在
<code>for j=1:thin ... end</code> 内部存在不必要的内存分配。</p><p>下面来进行验证。</p><h3 id=内存分配情况分析>内存分配情况分析</h3><p>取出循环内的一行代码，对它进行 profile ：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>using BenchmarkTools;
using Distributions;

@btime rand(Gamma(1.0, 1.0), 1)[1];
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>  39.136 ns (1 allocation: 96 bytes)
</code></pre></td></tr></table></div></div><p>奇怪，一个只返回一个 Float64 值的函数怎么会存在内存分配？仔细看 <code>[1]</code> 这个细节，
问题可能出在这里。通过查看文档，发现 <code>rand(Gamma(...), 1)</code> 中最后一个参数表示返回一个一维的 Array ，并且 Array 的大小是 1 ：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>using BenchmarkTools;
using Distributions;

@btime rand(Gamma(1.0, 1.0), 1)
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>  37.541 ns (1 allocation: 96 bytes)
1-element Array{Float64,1}:
 0.2929698750637693
</code></pre></td></tr></table></div></div><p>一个 Float64 的值有 64 位，共 8 字节（bytes），而刚刚代码中所返回只有一个
Float64 元素的 Array 竟然有 96 字节！既然我们每次只需要返回一个值，那为什么要画蛇添足去生成一个 Array 呢，直接调用只生成一个值的原型不好吗？</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>using BenchmarkTools;
using Distributions;

@btime rand(Gamma(1.0, 1.0), 1)
@btime rand(Gamma(1.0, 1.0))
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>  37.217 ns (1 allocation: 96 bytes)
1-element Array{Float64,1}:
 0.9938638399122478
  8.116 ns (0 allocations: 0 bytes)
1.8038508272928604
</code></pre></td></tr></table></div></div><p>看，直接使用 <code>rand(Gamma(...))</code> 耗时只有 <code>rand(Gamma(...), 1)</code> 的 22% ，并且内存的分配是 0 ！</p><p>有了这些结论，我们对 <code>JGibbs3</code> 修改后，有了下面的代码。</p><h3 id=去除内层循环的内存分配>去除内层循环的内存分配</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>using BenchmarkTools;
using Distributions;

function JGibbs4(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    for i = 1:N
        for j = 1:thin
            x = rand(Gamma(3, 1/(y*y + 4)))
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
        end
        mat[i,:] = [x,y]
    end
    mat
end

@btime JGibbs4(20000, 200);
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>JGibbs4 (generic function with 1 method)
  251.144 ms (20002 allocations: 2.14 MiB)
</code></pre></td></tr></table></div></div><p>这个耗时结果就正常多了，而且比调用 C-ffi 的版本还快了一丢丢；内存的分配也没那么夸张了。</p><h3 id=去除外层循环的内存分配>去除外层循环的内存分配</h3><p>但这并不是它的性能极限：它依然有 20002 次的内存分配。仔细观察外层循环部分，只有一个 <code>mat[i,:] = [x,y]</code> ，通常人们会认为编译器把它循环展开，不涉及内存分配，但事实并非如此：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>using BenchmarkTools

mat = zeros(Int, 2, 2);
@btime mat[1, :] = [1, 2];
@btime mat[:, 1] = [1, 2];
@btime begin
    mat[1, 1] = 1;
    mat[1, 2] = 2;
    end;
@btime begin
    mat[1, 1] = 1;
    mat[2, 1] = 2;
    end;
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>  259.485 ns (2 allocations: 112 bytes)
  220.621 ns (2 allocations: 112 bytes)
  28.665 ns (0 allocations: 0 bytes)
  27.603 ns (0 allocations: 0 bytes)
</code></pre></td></tr></table></div></div><p>我们可以得出三个结论：</p><ol><li>在使用切片赋值时会涉及内存分配，直接使用循环则不会；</li><li>小矩阵赋值时使用循环甚至手动展开循环性能更高；</li><li>Julia 的 Array 使用列主序，对第一个维度操作比对其它维度操作性能更高，但提升幅
度有限。</li></ol><p>于是我们把 <code>JGibbs4</code> 中外层循环的矩阵赋值展开，得到 <code>JGibbs5</code></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>using BenchmarkTools;
using Distributions;

function JGibbs5(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    for i = 1:N
        for j = 1:thin
            x = rand(Gamma(3, 1/(y*y + 4)))
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
        end
        mat[i,1] = x;
        mat[i,2] = y;
    end
    mat
end

@btime JGibbs5(20000, 200);
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>JGibbs5 (generic function with 1 method)
  229.861 ms (2 allocations: 312.58 KiB)
</code></pre></td></tr></table></div></div><p>它比 <code>JGibbs4</code> 又快了 20ms ！而且其中内存分配只有两次，已经相当令人满意了。如果要进一步压榨它的性能潜力，我们可以交换 <code>mat</code> 的行列，使外层循环每次赋值时都在访问第一个维度，限于篇幅原因，这里就不展开了。</p><h3 id=使用多线程加速>使用多线程加速</h3><p>上面使用的方法都是在一个线程内操作，现在的机器普遍都用上的多核处理器，而超算上更是单节点上配备了数十个处理器，如此多的计算资源不利用好岂不是暴殄天物。</p><p>那么 <code>JGibbs</code> 函数能被并行化吗？答案是肯定的。</p><p>它的内层循环粒度太小，线程切换的耗时占比太高，因此内层循环不适合并行化。而外层循环的粒度适中，我们试试将它并行化。</p><ul><li><p>直接使用 <code>Threads.@threads</code></p><p>Julia 原生支持多线程编程，并且提供了 <code>Threads.@threads</code> 宏来方便对循环并行化，于
是就有了下面的代码</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>println(&#34;nthreads = &#34;, Threads.nthreads())

using BenchmarkTools;
using Distributions;

function JGibbs6(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    Threads.@threads for i = 1:N
        for j = 1:thin
            x = rand(Gamma(3, 1/(y*y + 4)))
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
        end
        mat[i,1] = x;
        mat[i,2] = y;
    end
    mat
end

@btime JGibbs6(20000, 200);
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>nthreads = 6
JGibbs6 (generic function with 1 method)
  420.151 ms (52000035 allocations: 915.84 MiB)
</code></pre></td></tr></table></div></div><p><sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup></p><p>这个结果很离谱。先不谈运行时间，单看它的内存分配量就知道它绝对是有问题的（至于为
什么多出来这么多的内存分配，我也还在寻找原因，如果您有什么见解，请务必发邮件告诉
我 ^_^）， <code>Julia</code> 一共开了 6 个线程来加速，但结果显示它反而使运行效率降低了，问
题出在哪呢？仔细看代码</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>    x   = 0.
    y   = 0.
    Threads.@threads for i = 1:N
        for j = 1:thin
            x = rand(Gamma(3, 1/(y*y + 4)))
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
        end
        ...
    end
</code></pre></td></tr></table></div></div><p>每个线程内，都要对全局变量 <code>x</code> 和 <code>y</code> 进行修改，并且还要读取它们的值，这显然存在
竞争的现象。那如果把 <code>x</code> 和 <code>y</code> 移动到每个线程内部定义呢？</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>println(&#34;nthreads = &#34;, Threads.nthreads())

using BenchmarkTools;
using Distributions;

function JGibbs6_1(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    Threads.@threads for i = 1:N
        x   = rand()
        y   = rand()
        for j = 1:thin
            x = rand(Gamma(3, 1/(y*y + 4)))
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
        end
        mat[i,1] = x;
        mat[i,2] = y;
    end
    mat
end

@btime JGibbs6_1(20000, 200);
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>nthreads = 6
JGibbs6_1 (generic function with 1 method)
  39.926 ms (33 allocations: 316.75 KiB)
</code></pre></td></tr></table></div></div><p>这个结果相当令人满意了，内存的分配降低很多，看来读写全局的变量对并发程序性能影响
还是不容忽略！</p></li></ul><ul><li><p>对外层循环分组后并行</p><p>除了直接用 <code>@threads</code> ，我们还可以手动对外部循环分组嘛，然后每个线程分配到一小段
连续的外层循环，相当于粒度更大。</p><p><code>Iterators</code> 提供了对 <code>Array</code> 分组的方法：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>help?&gt; Iterators.partition
  partition(collection, n)

  Iterate over a collection n elements at a time.

  Examples
  ≡≡≡≡≡≡≡≡≡≡

  julia&gt; collect(Iterators.partition([1,2,3,4,5], 2))
  3-element Array{SubArray{Int64,1,Array{Int64,1},Tuple{UnitRange{Int64}},true},1}:
   [1, 2]
   [3, 4]
   [5]
</code></pre></td></tr></table></div></div><p>利用这个函数，我们对外层循环的下标分组，然后每个线程只操作一组下标，这样有效避免了数据竞争发生。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>using BenchmarkTools;
using Distributions;

println(&#34;nthreads = &#34;, Threads.nthreads())

function JGibbs7(N::Int, thin::Int)
  nt = Threads.nthreads()

  # mat = zeros(Float64, N, 2)
  mat = zeros(Float64, N, 2)

  # partition
  parts = Iterators.partition(1:N, N ÷ Threads.nthreads() + 1) |&gt; collect

  Threads.@threads for p in parts
    x   = 0.
    y   = 0.
    for i in p
      for j in 1:thin
        x = rand(Gamma(3, 1/(y^2 + 4)))
        y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
      end
      mat[i,1] = x
      mat[i,2] = y
    end
  end

  mat
end

@btime JGibbs7(20000, 200);
</code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-text data-lang=text>nthreads = 6
JGibbs7 (generic function with 1 method)
  41.631 ms (34 allocations: 316.91 KiB)
</code></pre></td></tr></table></div></div><p>这个结果和 <code>JGibbs6_1</code> 相差不大，都是已经充分利用了 6 个线程的计算资源。</p></li></ul><h2 id=总结>总结</h2><p>本文从一名用户的角度，浅显地阐述了如何对一个函数进行优化，以及如何使用各类工具来帮助我们分析程序的运行状况。我得出以下几个结论，供大家参考：</p><ol><li>使用纯 Julia 编写的程序性能的 <strong>上限</strong> 很高，完全不输于调用 FFI ，因此大家对此
不应有过多的顾虑，直接用就完事了；</li><li>尽管我们认为处理器的计算是耗时大头，程序运行时的内存反复分配也可能成为程序运
行的瓶颈；</li><li>在使用并发加速时应格外小心是否存在竞争的风险，能做到内聚就尽量做到内聚，否则
将来总会掉到坑里；</li><li>想发挥出 Julia 真正的性能，还是需要下一些功夫的，随手一写还真不一定比其它语言
快；好在 Julia 社区提供了实用的性能分析工具，大大简化了优化的流程，这一点我十
分赞赏。</li></ol><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>代码来自三爷的 gist : <a href=https://gist.github.com/MitsuhaMiyamizu/5edf031a36cfb260381a70060a3fea4a>https://gist.github.com/MitsuhaMiyamizu/5edf031a36cfb260381a70060a3fea4a</a> <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>这里使用 BenchmarkTools 中的 <code>@btime</code> 而不是 <code>@time</code> 是因为后者并不能将代 码编译的时间去掉，前者则能多次执行，取耗时最小值，有效避免了 AOT 对计时的影响。 <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>ffi 即 Foreign function interface ，用于跨语言调函数，详见 <a href=https://en.wikipedia.org/wiki/Foreign%5Ffunction%5Finterface>https://en.wikipedia.org/wiki/Foreign%5Ffunction%5Finterface</a> <a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p>我在启动 <code>julia</code> 前对环境变量进行了修改 <code>export JULIA_NUM_THREADS=6</code> ，这 样 Julia 在运行时支持最大 6 个线程操作。 <a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>Ionizing</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2021-04-16</span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=http://ionizing.page/tags/posts/>Posts</a>
<a href=http://ionizing.page/tags/julia/>Julia</a>
<a href=http://ionizing.page/tags/optimization/>Optimization</a>
<a href=http://ionizing.page/tags/parallelprogramming/>ParallelProgramming</a></div><nav class=post-nav><a class=prev href=/post/vasp-convergence-test-scripts/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">VASP 收敛性测试的小脚本</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/a-new-journey/><span class="next-text nav-default">新的旅程</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697c-11.777231-11.500939-30.216186-10.304694-41.178865 2.712784z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=mailto:petersmith_9@outlook.com rel="me noopener" class=iconfont title=email><svg class="icon" viewBox="0 0 1451 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408h399.992405s71.046998 3.997201 71.046998 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zm53.281707 130.131124C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523S0 1024 83.726336 1024H682.532949 753.579947h595.368192C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955c-39.771477 34.470494-74.671786 43.295855-98.955861 43.868928z"/></svg></a><a href=http://github.com/Ionizing rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04C242.005334 929.664 211.968 830.08 211.968 830.08 188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=http://ionizing.page/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2021
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>Ionizing</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script><script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script><script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script><script type=text/javascript src=/js/load-photoswipe.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>