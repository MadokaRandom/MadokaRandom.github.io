:CONFIG:
#+HUGO_BASE_DIR: ../
#+HUGO_FRONT_MATTER_FORMAT: yaml
#+SETQ_TODO: TODO DRAFT DONE
#+PROPERTY: header-args :eval never-export
#+OPTIONS: toc:2 author:nil
:END:


* Table of Contents    :TOC_2:
- [[#about][About]]
- [[#external-link][External-link]]
- [[#posts][Posts]]
  - [[#新的旅程][新的旅程]]
  - [[#记一次-julia-代码性能优化过程][记一次 Julia 代码性能优化过程]]
  - [[#镜像态浅析--从-dft-计算的角度][镜像态浅析--从 DFT 计算的角度]]
  - [[#rsgrad-开发收获][Rsgrad 开发收获]]
  - [[#vasp-收敛性测试的小脚本][VASP 收敛性测试的小脚本]]
  - [[#组内集群折腾实录][组内集群折腾实录]]

* DONE About :about:
CLOSED: [2021-4-13 Tue]
:PROPERTIES:
:EXPORT_FILE_NAME: about
:EXPORT_HUGO_SECTION: ./
:EXPORT_HUGO_MENU: :menu main
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :weight 50
:EXPORT_DATE: [2021-04-13]
:END:

A Ph.D candidate who majors in physical chemistry.

| Abilities | Level[fn:1] |
|-----------+-------------|
| C/C++     | Beginner    |
| Rust      | Beginner    |
| LaTeX     | Newbie      |
| VASP      | Beginner    |
| Linux     | Beginner    |

[fn:1] https://english.stackexchange.com/questions/83832/list-of-expertise-levels-from-beginner-to-expert


* DONE External-link
CLOSED: [2021-04-16 Fri 21:26]
:PROPERTIES:
:EXPORT_FILE_NAME: external-link
:EXPORT_HUGO_SECTION: ./
:EXPORT_HUGO_MENU: :menu main
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :weight 60
:EXPORT_DATE: [2021-04-16]
:END:

|-----------+-----------------------------------|
| Person    | Link                              |
|-----------+-----------------------------------|
| Liam0205  | https://liam.page/about/          |
| Mr. Joker | https://mrjokersince1997.gitee.io |
|-----------+-----------------------------------|


* Posts                :Posts:
:PROPERTIES:
:EXPORT_HUGO_SECTION: post
:END:

** DONE 新的旅程 :@杂项:回归:模板:配置:
CLOSED: [2021-04-14 Wed 16:15]
:PROPERTIES:
:EXPORT_FILE_NAME: a-new-journey
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :katex true :markup goldmark
:END:

这是回归博客写作后的第一篇文章

#+hugo: more

*** 回归
时光荏冉，已经好久没有更新博客了，上一次写博客还是去年寒假疫情在家时期。

这一年多以来总算把与实验组合作的几个工作结束了（第一次实践使用 VASP ），这几个工
作感觉能总结的地方不多，都是细节居多，但坑还是不少的。我自己的工作做了快两年了
（看来平时没少摸鱼），在去年底它的进度有了 180 度转变，这还多亏了导师的嘱托，让
我在补充图表时 Review 了一下之后的结果，一看就发现之前的结论完全错误，于是重新跑
了一下 NAMD ，这次的结果终于符合「预期」了，但现在似乎又遇到了一些不大不小的问题，
即能带交叉的处理，目测解决它又要费些时间了（而且还中间还有其它实验组的东西要做）。

说了这段时间自己在做什么，下面就该讲博客相关的东西了。

*** 博客相关
关于博客，我这次决心将它迁移到 Hugo 框架下，配合 Org-mode 和 ox-hugo 使用，至少
到现在体验挺好：
- Hugo 很快，生成静态页面耗时在 ms 量级，比 Hexo 不知道高到哪里去了；
- Org-mode 很强大，谁用谁知道；
- 私以为 Jane 主题足够简约，也留了足够的空间折腾。

近期做了些工作，我会把心得总结起来放到博客上，供自己和小伙伴们参考～

**** 配置、模板
以下是写博客时可能要用到的一些模板/配置，仅供自己参考了。

- Org-mode 中 CJK 文档的 soft space 问题，已经有人给出了解决方案[fn:: http://zwz.github.io] ：
#+begin_src elisp
(defun clear-single-linebreak-in-cjk-string (string)
"clear single line-break between cjk characters that is usually soft line-breaks"
(let* ((regexp "\\([\u4E00-\u9FA5]\\)\n\\([\u4E00-\u9FA5]\\)")
        (start (string-match regexp string)))
    (while start
    (setq string (replace-match "\\1\\2" nil nil string)
            start (string-match regexp string start))))
string)

(defun ox-html-clear-single-linebreak-for-cjk (string backend info)
(when (org-export-derived-backend-p backend 'html)
    (clear-single-linebreak-in-cjk-string string)))

(eval-after-load "ox"
  '(add-to-list 'org-export-filter-final-output-functions
                'ox-html-clear-single-linebreak-for-cjk))
#+end_src
- 添加链接时使用 src_elisp[:exports code]{C-c C-l} ， Doom-Emacs 会提示你输入链
   接的 URL 和 description；
- 使用 Inline code 时，参考它[fn:: https://stackoverflow.com/questions/16186843/inline-code-in-org-mode/16193498#16193498]： =src_sh[:exports code]{echo -e "test"}= ；
- =:PROPERTIES:= 中 =:@cat:= 定义了一个 category =cat= ， =:foo:= 定义了一个 tag =foo= ，
  =:@cat:foo:bar:= 则分别定义了一个 category =cat= ，两个 tags =foo= 、 =bar= ；
- 每篇文章标题前使用 =S-left= 或 =S-right= 可以切换 =TODO= 和 =DONE= 的状态；输
  入数学公式时，需要在 subtree 的 =:PROPERTIES:= 里加上
  =:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :katex true :markup goldmark= 。

   此时 =\(F=ma\)= 表示 inline equation ，输出 \(F=ma\) ； =\[F=ma\]= 表示
  displaystyle equation 。（冷知识[fn::
  https://orgmode.org/worg/org-tutorials/org-latex-preview.html]： Orgmode 支持
  即时渲染公式： =C-c C-x C-l= 会把当前公式渲染好并以 png 的形式插入当前窗口，重
  复这个操作可以关闭预览）

   现在试试一个稍稍复杂点的公式：

\[ \begin{aligned} \nabla \times \vec{\mathbf{B}} - \frac1c
\frac{\partial\vec{\mathbf{E}}}{\partial t} & = \frac{4\pi}{c}\vec{\mathbf{j}}
\newline \nabla \cdot \vec{\mathbf{E}} & = 4 \pi \rho \newline \nabla \times
\vec{\mathbf{E}} + \frac1c \frac{\partial\vec{\mathbf{B}}}{\partial t} & =
\vec{\mathbf{0}} \newline \nabla \cdot \vec{\mathbf{B}} & = 0 \end{aligned} \]

- 使用脚注来代替文献的上标[fn:: https://orgmode.org/manual/Creating-Footnotes.html]
  ，有三种方式：
  1. 声明和定义分离的脚注：在要添加脚注的地方声明 =[fn:NAME]= ，然后在其它地方定
     义这个脚注 =[fn:NAME] some description here ...= ；
  2. 行内定义的脚注：直接使用 =[fn:: some description here ... ]= ，这种方法不需要命名，可谓对程序员十分友好了 23333 ；
  3. 带名字的行内脚注： =[fn:NAME: some description here ...]= 。

**** 图片等外部文件的引用
这一节单独列出来是因为它比数学公式还要难处理，根据 =ox-hugo=[fn:: https://ox-hugo.scripter.co] 的说明，现在有三种引用图片的方法：

1. 使用相对路径：直接把图片放到 =<HUGO_BASE_DIR>/static/= 里，然后引用时可以省略
   =<HUGO_BASE_DIR>/static/= 前缀，例如有一个文件路径是
   =<HUGO_BASE_DIR>/static/image/foo.png= ，引用它时可以这样写：
   =[[image/foo.png]]= ；
2. 使用绝对路径：例如有一个路径是 =~/some/path/foo.png= ，引用它时可以使用
   =[[~/some/path/foo.png]]= ，此时不光在 orgmode 里可以直接预览图片， =ox-hugo=
   在导出时还会把它复制到 =<HUGO_BASE_DIR>/static/ox-hugo/= 里并生成链接；
3. 使用图床：现在 GitHub ， GitLab 等也可以用作图床，并且有成熟的软件来做这件事
   比如 PicGo[fn:: https://github.com/Molunerfinn/PicGo] 。把图片传给图床后，图
   床会返回一个链接，直接把它贴在 orgmode 里就能实现引用图片的效果。但之前我用七
   牛云的图床一段时间后七牛云直接拒绝被薅，改了域名，我也就对图床产生一些顾虑
   +，而且使用图床后一个缺点是，它降低了每篇文章的内聚度，增加了对外部的耦合（掉个
   书袋233）+ 。

因此我还是决定把图片等外部文件放在 =<HUGO_BASE_DIR>/content-org/= 里，每篇文章单
独建一个文件夹，然后使用相对路径引用。下面是效果展示（它使用了
=[[./a-new-journey/himehina.jpeg]]= ）：[[./a-new-journey/himehina.jpeg]]


** DONE 记一次 Julia 代码性能优化过程 :@Programming:Julia:Optimization:ParallelProgramming:
CLOSED: [2021-04-16 Fri 13:06]
:PROPERTIES:
:EXPORT_FILE_NAME: a-try-on-julia-code-optimization
:EXPORT_DATE: [2021-04-16]
:END:

这是和某三爷讨论后对交流内容的整理。

#+hugo: more

众所周知， Julia 是一种高级通用动态编程语言，它专为科学计算而生。为了方便科研人
员使用，它的语法被设计得很像 MATLAB ，但比 MATLAB 更合理（譬如数组引用使用 =[]=
，而不是 =()= ）。作为一门很年轻的语言，它吸收了前辈们的很多优点，也有着自己的特
色，但最受人青睐的一点在于：尽管它是一门动态语言，却宣称拥有 C/C++ 一般的性能。
一般而言，动态语言的表现能力更为出色，能用更少的代码做更多的事，开发效率高；而静
态语言的编译器后端更容易优化，运行效率高。Julia 有动态性，开发效率毋庸置疑，一些
测评也显示 Julia 确实拥有很强的性能，但这是否意味着你随手写的一段代码就能有很高
并且达到预期的性能？我看未必。

*** 运行环境

| Processor | Intel Core i5 9600KF |
| Memory    | 16GB 3200MHz         |
| OS        | macOS 10.15.6        |
| Julia     | 1.5.1                |

*** 优化过程
**** 原始版本[fn:1]
废话不多说，直接开始正题，先来看今天的主角[fn:2]
#+begin_src ess-julia :results output :session *julia*
using Rmath;
using BenchmarkTools;

function JGibbs1(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    for i = 1:N
        for j = 1:thin
            x = rgamma(1, 3, 1/(y*y + 4))[1]
            y = rnorm(1, 1/(x+1), 1/sqrt(2(x + 1)))[1]
        end
        mat[i,:] = [x,y]
    end
    mat
end;

@btime JGibbs1(20000, 200);
#+end_src

这是一段关于 Gibbs 采样的代码，它主要由两个循环组成，外部循环一次产生两个值，内
部循环是迭代式的，即下一次循环要用到上次循环的结果。很明显它引入了 R 的库，并用
R 的 =rgamma= 和 =rnorm= 实现，那么它的性能是怎样的呢？

#+RESULTS:
:   501.798 ms (8020002 allocations: 734.56 MiB)

根据原文的说法，它的性能已经比 =Rgibbs= 快 17 倍，比 =RCgibbs= 快 13 倍，已经是
比较令人满意的结果了。

**** 使用 C-ffi 的 =rgamma= 与 =rnorm=[fn:1]

由于直接用 R 写的代码可能并不是最快的，而且它还在内层循环里，所以我们有理由相信
使用 C-ffi[fn:3] 版的 =rgamma= 与 =rnorm= 会更快。

#+begin_src ess-julia :results output :session *julia* :exports both
using Rmath
import Rmath: libRmath
using BenchmarkTools
function JGibbs2(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    for i = 1:N
        for j = 1:thin
            x = ccall((:rgamma, libRmath), Float64, (Float64, Float64), 3., 1/(y*y + 4))
            y = ccall((:rnorm, libRmath), Float64, (Float64, Float64), 1/(x+1), 1/sqrt(2*(x + 1)))
        end
        mat[i,:] = [x,y]
    end
    mat
end

@btime JGibbs2(20000, 200);
#+end_src

#+RESULTS:
: JGibbs2 (generic function with 1 method)
:   259.387 ms (20002 allocations: 2.14 MiB)

果然，使用 C-ffi 版的函数后性能又提升了一倍！

**** 去除外部依赖[fn:1]

尽管使用 C 的实现后， =JGibbs= 性能提升巨大，但依赖外部库多少有点让人感觉不爽，
毕竟它和 Julia 所宣称的高性能关系不是很大（核心部分是 C 的贡献，而不是 Julia）。
既然 Julia 也是高性能语言，何不拿纯 Julia 写一个 =JGibbs= 来比比？

Julia 是为科学计算而生，它的社区维护了一个统计学库 =Distributions= ，里面包含了
=gamma= 与 =norm= 分布的函数，可以用来替换 =rgamma= 和 =rnorm= ，写完之后是这个
样子：

#+begin_src ess-julia :results output :session *julia* :exports both
using BenchmarkTools;
using Distributions;

function JGibbs3(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    for i = 1:N
        for j = 1:thin
            x = rand(Gamma(3, 1/(y^2 + 4)), 1)[1]
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))), 1)[1]
        end
        mat[i,:] = [x,y]
    end
    mat
end

@btime JGibbs3(20000, 200);
#+end_src

#+RESULTS:
: JGibbs3 (generic function with 1 method)
:   550.624 ms (8020002 allocations: 734.56 MiB)

咦？看起来它还没有使用 R-ffi 的函数快！

那么问题出在哪呢？仔细看结果，除了时间之外还有两个数据，一个是执行一次该函数时所
分配内存的次数，另一个是函数执行期间分配内存的总量。我们回头看一下使用 C-ffi 的
版本，它的测试结果显示除了性能更强外，内存分配的次数和总量也更少！而且 8020002
恰好是 20002 的 400 倍左右，正好是 =thin=200= 的 2 倍。据此，我们可以猜想，在
=for j=1:thin ... end= 内部存在不必要的内存分配。

下面来进行验证。

**** 内存分配情况分析
取出循环内的一行代码，对它进行 profile ：
#+begin_src ess-julia :results output :session *julia* :exports both
using BenchmarkTools;
using Distributions;

@btime rand(Gamma(1.0, 1.0), 1)[1];
#+end_src

#+RESULTS:
:   39.136 ns (1 allocation: 96 bytes)

奇怪，一个只返回一个 Float64 值的函数怎么会存在内存分配？仔细看 =[1]= 这个细节，
问题可能出在这里。通过查看文档，发现 =rand(Gamma(...), 1)= 中最后一个参数表示返
回一个一维的 Array ，并且 Array 的大小是 1 ：
#+begin_src ess-julia :results output :session *julia* :exports both
using BenchmarkTools;
using Distributions;

@btime rand(Gamma(1.0, 1.0), 1)
#+end_src

#+RESULTS:
:   37.541 ns (1 allocation: 96 bytes)
: 1-element Array{Float64,1}:
:  0.2929698750637693

一个 Float64 的值有 64 位，共 8 字节（bytes），而刚刚代码中所返回只有一个
Float64 元素的 Array 竟然有 96 字节！既然我们每次只需要返回一个值，那为什么要画
蛇添足去生成一个 Array 呢，直接调用只生成一个值的原型不好吗？

#+begin_src ess-julia :results output :session *julia* :exports both
using BenchmarkTools;
using Distributions;

@btime rand(Gamma(1.0, 1.0), 1)
@btime rand(Gamma(1.0, 1.0))
#+end_src

#+RESULTS:
:   37.217 ns (1 allocation: 96 bytes)
: 1-element Array{Float64,1}:
:  0.9938638399122478
:   8.116 ns (0 allocations: 0 bytes)
: 1.8038508272928604

看，直接使用 =rand(Gamma(...))= 耗时只有 =rand(Gamma(...), 1)= 的 22% ，并且内存
的分配是 0 ！

有了这些结论，我们对 =JGibbs3= 修改后，有了下面的代码。

**** 去除内层循环的内存分配
#+begin_src ess-julia :results output :session *julia* :exports both
using BenchmarkTools;
using Distributions;

function JGibbs4(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    for i = 1:N
        for j = 1:thin
            x = rand(Gamma(3, 1/(y*y + 4)))
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
        end
        mat[i,:] = [x,y]
    end
    mat
end

@btime JGibbs4(20000, 200);
#+end_src

#+RESULTS:
: JGibbs4 (generic function with 1 method)
:   251.144 ms (20002 allocations: 2.14 MiB)

这个耗时结果就正常多了，而且比调用 C-ffi 的版本还快了一丢丢；内存的分配也没那么夸张了。

**** 去除外层循环的内存分配

但这并不是它的性能极限：它依然有 20002 次的内存分配。仔细观察外层循环部分，只有
一个 =mat[i,:] = [x,y]= ，通常人们会认为编译器把它循环展开，不涉及内存分配，但事
实并非如此：

#+begin_src ess-julia :results output :session *julia* :exports both
using BenchmarkTools

mat = zeros(Int, 2, 2);
@btime mat[1, :] = [1, 2];
@btime mat[:, 1] = [1, 2];
@btime begin
    mat[1, 1] = 1;
    mat[1, 2] = 2;
    end;
@btime begin
    mat[1, 1] = 1;
    mat[2, 1] = 2;
    end;
#+end_src

#+RESULTS:
:   259.485 ns (2 allocations: 112 bytes)
:   220.621 ns (2 allocations: 112 bytes)
:   28.665 ns (0 allocations: 0 bytes)
:   27.603 ns (0 allocations: 0 bytes)

我们可以得出三个结论：
1. 在使用切片赋值时会涉及内存分配，直接使用循环则不会；
2. 小矩阵赋值时使用循环甚至手动展开循环性能更高；
3. Julia 的 Array 使用列主序，对第一个维度操作比对其它维度操作性能更高，但提升幅
   度有限。

于是我们把 =JGibbs4= 中外层循环的矩阵赋值展开，得到 =JGibbs5=

#+begin_src ess-julia :results output :session *julia* :exports both
using BenchmarkTools;
using Distributions;

function JGibbs5(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    for i = 1:N
        for j = 1:thin
            x = rand(Gamma(3, 1/(y*y + 4)))
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
        end
        mat[i,1] = x;
        mat[i,2] = y;
    end
    mat
end

@btime JGibbs5(20000, 200);
#+end_src

#+RESULTS:
: JGibbs5 (generic function with 1 method)
:   229.861 ms (2 allocations: 312.58 KiB)

它比 =JGibbs4= 又快了 20ms ！而且其中内存分配只有两次，已经相当令人满意了。如果
要进一步压榨它的性能潜力，我们可以交换 =mat= 的行列，使外层循环每次赋值时都在访
问第一个维度，限于篇幅原因，这里就不展开了。

**** 使用多线程加速

上面使用的方法都是在一个线程内操作，现在的机器普遍都用上的多核处理器，而超算上更
是单节点上配备了数十个处理器，如此多的计算资源不利用好岂不是暴殄天物。

那么 =JGibbs= 函数能被并行化吗？答案是肯定的。

它的内层循环粒度太小，线程切换的耗时占比太高，因此内层循环不适合并行化。而外层循
环的粒度适中，我们试试将它并行化。

****** 直接使用 =Threads.@threads=

Julia 原生支持多线程编程，并且提供了 =Threads.@threads= 宏来方便对循环并行化，于
是就有了下面的代码
#+begin_src ess-julia :results output :exports both :session *julia*
println("nthreads = ", Threads.nthreads())

using BenchmarkTools;
using Distributions;

function JGibbs6(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    x   = 0.
    y   = 0.
    Threads.@threads for i = 1:N
        for j = 1:thin
            x = rand(Gamma(3, 1/(y*y + 4)))
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
        end
        mat[i,1] = x;
        mat[i,2] = y;
    end
    mat
end

@btime JGibbs6(20000, 200);
#+end_src

#+RESULTS:
: nthreads = 6
: JGibbs6 (generic function with 1 method)
:   420.151 ms (52000035 allocations: 915.84 MiB)
[fn:: 我在启动 =julia= 前对环境变量进行了修改 =export JULIA_NUM_THREADS=6= ，这
样 Julia 在运行时支持最大 6 个线程操作。]

这个结果很离谱。先不谈运行时间，单看它的内存分配量就知道它绝对是有问题的（至于为
什么多出来这么多的内存分配，我也还在寻找原因，如果您有什么见解，请务必发邮件告诉
我 ^_^）， =Julia= 一共开了 6 个线程来加速，但结果显示它反而使运行效率降低了，问
题出在哪呢？仔细看代码

#+begin_src ess-julia
    x   = 0.
    y   = 0.
    Threads.@threads for i = 1:N
        for j = 1:thin
            x = rand(Gamma(3, 1/(y*y + 4)))
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
        end
        ...
    end
#+end_src

每个线程内，都要对全局变量 =x= 和 =y= 进行修改，并且还要读取它们的值，这显然存在
竞争的现象。那如果把 =x= 和 =y= 移动到每个线程内部定义呢？

#+begin_src ess-julia :results output :session *julia* :exports both
println("nthreads = ", Threads.nthreads())

using BenchmarkTools;
using Distributions;

function JGibbs6_1(N::Int, thin::Int)
    mat = zeros(Float64, N, 2)
    Threads.@threads for i = 1:N
        x   = rand()
        y   = rand()
        for j = 1:thin
            x = rand(Gamma(3, 1/(y*y + 4)))
            y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
        end
        mat[i,1] = x;
        mat[i,2] = y;
    end
    mat
end

@btime JGibbs6_1(20000, 200);
#+end_src

#+RESULTS:
: nthreads = 6
: JGibbs6_1 (generic function with 1 method)
:   39.926 ms (33 allocations: 316.75 KiB)

这个结果相当令人满意了，内存的分配降低很多，看来读写全局的变量对并发程序性能影响
还是不容忽略！

****** 对外层循环分组后并行

除了直接用 =@threads= ，我们还可以手动对外部循环分组嘛，然后每个线程分配到一小段
连续的外层循环，相当于粒度更大。

=Iterators= 提供了对 =Array= 分组的方法：
#+begin_src text
help?> Iterators.partition
  partition(collection, n)

  Iterate over a collection n elements at a time.

  Examples
  ≡≡≡≡≡≡≡≡≡≡

  julia> collect(Iterators.partition([1,2,3,4,5], 2))
  3-element Array{SubArray{Int64,1,Array{Int64,1},Tuple{UnitRange{Int64}},true},1}:
   [1, 2]
   [3, 4]
   [5]
#+end_src

利用这个函数，我们对外层循环的下标分组，然后每个线程只操作一组下标，这样有效避免了数据竞争发生。
#+begin_src ess-julia :results output :session *julia* :exports both
using BenchmarkTools;
using Distributions;

println("nthreads = ", Threads.nthreads())

function JGibbs7(N::Int, thin::Int)
  nt = Threads.nthreads()

  # mat = zeros(Float64, N, 2)
  mat = zeros(Float64, N, 2)

  # partition
  parts = Iterators.partition(1:N, N ÷ Threads.nthreads() + 1) |> collect

  Threads.@threads for p in parts
    x   = 0.
    y   = 0.
    for i in p
      for j in 1:thin
        x = rand(Gamma(3, 1/(y^2 + 4)))
        y = rand(Normal(1/(x + 1), 1/sqrt(2*(x + 1))))
      end
      mat[i,1] = x
      mat[i,2] = y
    end
  end

  mat
end

@btime JGibbs7(20000, 200);
#+end_src

#+RESULTS:
: nthreads = 6
: JGibbs7 (generic function with 1 method)
:   41.631 ms (34 allocations: 316.91 KiB)

这个结果和 =JGibbs6_1= 相差不大，都是已经充分利用了 6 个线程的计算资源。


*** 总结
本文从一名用户的角度，浅显地阐述了如何对一个函数进行优化，以及如何使用各类工具来
帮助我们分析程序的运行状况。我得出以下几个结论，供大家参考：
1. 使用纯 Julia 编写的程序性能的 *上限* 很高，完全不输于调用 FFI ，因此大家对此
   不应有过多的顾虑，直接用就完事了；
2. 尽管我们认为处理器的计算是耗时大头，程序运行时的内存反复分配也可能成为程序运
   行的瓶颈；
3. 在使用并发加速时应格外小心是否存在竞争的风险，能做到内聚就尽量做到内聚，否则
   将来总会掉到坑里；
4. 想发挥出 Julia 真正的性能，还是需要下一些功夫的，随手一写还真不一定比其它语言
   快；好在 Julia 社区提供了实用的性能分析工具，大大简化了优化的流程，这一点我十
   分赞赏。

[fn:1] 代码来自三爷的 gist :
https://gist.github.com/MitsuhaMiyamizu/5edf031a36cfb260381a70060a3fea4a
[fn:2] 这里使用 BenchmarkTools 中的 =@btime= 而不是 =@time= 是因为后者并不能将代 码编译的时间去掉，前者则能多次执行，取耗时最小值，有效避免了 AOT 对计时的影响。
[fn:3] ffi 即 Foreign function interface ，用于跨语言调函数，详见
https://en.wikipedia.org/wiki/Foreign_function_interface


** TODO 镜像态浅析--从 DFT 计算的角度
:PROPERTIES:
# :EXPORT_FILE_NAME: brief-analysis-of-ips-from-dft-perspective
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :katex true :markup goldmark
:END:

本文将从 DFT 计算的角度谈谈

#+hugo: more

** TODO Rsgrad 开发收获

** DONE VASP 收敛性测试的小脚本 :@PhysicalChemistry:VASP:Shell:ASE:
CLOSED: [2021-04-16 Fri 20:57]
:PROPERTIES:
:EXPORT_FILE_NAME: vasp-convergence-test-scripts
:EXPORT_DATE: [2021-04-16]
:END:

一般而言，在使用 VASP 计算体系之前都需要对一些参数做收敛性测试，侯老师[fn:: https://github.com/orivenlikon/vaspDoc/blob/master/%5Bmuchong.com%5Dvasp入门指南-复旦-侯柱峰.pdf]
曾写过一本VASP 入门手册，里面给了一些测试计算参数的小脚本，这里我
也给出一些我经常用的收敛性测试脚本，权当抛砖引玉了。

#+hugo: more

本文提供的测试脚本可以写进提交任务的脚本中，进而充分利用超算上多核、多节点的计算
资源。需要注意的是，这些脚本本身并不产生 VASP 的输入文件，而是在已有的文件基础上
进行修改。

*** =SIGMA= 的测试
和上面的使用前提一样， INCAR 应提前准备好。 SIGMA 收敛的标准通常是 dE 绝对值小于
1.0meV/atom 。

#+begin_src sh
#!/bin/bash
#SBATCH xx
...

set -e
set -o pipefail

VASP_EXEC="srun /path/to/vasp"  # "mpirun -np xxx" is also ok

date >> sigma.txt
for i in 0.8 0.5 0.3 0.1 0.08 0.05 ; do
    echo
    sed -i "s/^.*\\bSIGMA\\b.*$/        SIGMA = $i" INCAR
    eval ${VASP_EXEC}
    TS=$(grep "EENTRO" OUTCAR | tail -1 | awk '{print $5}')
    echo "$i    $TS" >> sigma.txt
done

echo "NIONS = " $(grep NIONS OUTCAR | awk '{print $12}') >> sigma.txt
#+end_src

*** =ENCUT= 的测试
使用前请先写好一个 INCAR ，并确保里面包含 =ENCUT= 字段，且 =ENCUT= 单独占一行
（否则同一行内的其它参数会被舍去）。通常而言，达到收敛的标志是相邻两次迭代的能量
小于 1.0meV/atom 。

#+begin_src sh
#!/bin/bash
#SBATCH xx
...

set -e
set -o pipefail

VASP_EXEC="srun /path/to/vasp"  # "mpirun -np xxx" is also ok

date >> encut.txt
for i in {200..500..50}; do
    sed -i "s/^.*\\bENCUT\\b.*$/        ENCUT = $i" INCAR
    eval ${VASP_EXEC}
    E=$(grep TOTEN OUTCAR | tail -1 | awk '{printf "%12.6f", $5}')  # Extract TOTEN from OUTCAR
    echo "$i    $E" >> encut.txt
done

echo "NIONS = " $(grep NIONS OUTCAR | awk '{print $12}') >> encut.txt
#+end_src

*** 晶格参数的测试
**** 晶格常数的测试

执行这个测试需要准备好 POSCAR ，这个测试不依赖 ASE 等包，因为它实质上是在更改
POSCAR 第二行的 scale factor 。这个测试只是相对粗糙的测试，因此这里就直接在原位
覆盖前一次的计算结果了。

#+begin_src sh
#!/bin/bash
#SBATCH xx
...

set -e
set -o pipefail

VASP_EXEC="srun /path/to/vasp"  # "mpirun -np xxx" is also ok

date >> a.txt
for i in $(seq 0.99 0.001 1.01)
do
  sed -i "2c $i" POSCAR
  echo -e "a = $i angstrom"
  eval ${VASP_EXEC}
  E=`grep "TOTEN" OUTCAR | tail -1 | awk '{printf "%12.6f", $5 }'`
  V=`grep "volume" OUTCAR | tail -1 | awk '{printf "%12.4f", $5}'`
  printf "a = %6.3f Vol = %10.4f Energy = %18.10f\n" $i $V $E >> a.txt
  tail -1 a.txt
done
echo -e "\n\n" >> a.txt#+end_src
#+end_src

**** 晶格长度的测试
在测试晶格的角度、长度时就不得不使用其它包了，Python 的 ASE 包提供了相对完善的基
础设施，这里在使用它来辅助完成晶格测试的工作。另外，在测试 Slab 的真空层厚度时也
可以使用这个脚本[fn:: 这个脚本要求晶格的 c 轴垂直于 a 轴和 b 轴]。

#+begin_src python
#!/usr/bin/env python3

import os
from ase.io import read as poscar_reader

poscar = poscar_reader("POSCAR")
cell = poscar.get_cell().copy()

for i in range(1, 7):
    cell[-1, -1] += 5.0             # Increase length along z axis by 5 angstroms each time
    poscar.set_cell(cell)
    dirname = "{:02}".format(i*5)
    if not os.path.exists(dirname):
        os.mkdir(dirname)           # create directories for each test
    poscar.write(dirname + "/POSCAR", vasp5=True, direct=True)
    for infile in ['INCAR', 'POTCAR', 'KPOINTS', 'sub_vasp_tahoma']:
        abspath = os.path.abspath(infile)
        os.symlink(abspath, dirname + "/" + infile)
        pass
    print("POSCAR saved in {}".format(dirname + "/POSCAR"))
    pass
#+end_src

用户可以根据自己需要随意更改晶格的参数，具体的需求可以通过阅读 ASE 的文档[fn::
https://wiki.fysik.dtu.dk/ase/ase/atoms.html 和
https://wiki.fysik.dtu.dk/ase/ase/geometry.html]来实现，这里就不一一列举了。

*** Slab 衬底层数的测试
一般而言，结构建模都是在 Materials Studio 上完成的（我现在也是如此），但如果有对
Slab 衬底做收敛性测试的需求，还是要借助一下 ASE ，它也内置一了些常见的 Slab 。

下面是一个生成不同层数 Ag(111) Slab 的脚本：

#+begin_src python
#!/usr/bin/env python3

import os
import numpy as np
from ase.build import fcc111
from ase.constraints import FixAtoms

for i in np.arange(1, 9):
    numstr = str(i)

    # generate 1x1 slab along a and b axis, this slab has `i` layers
    # vacuum is 20 angstrom
    slab = fcc111("Ag", size=(1, 1, i), vacuum=20)

    # Relax the first 2 layers and fix the others.
    c = FixAtoms(mask=[atom.tag > 2 for atom in slab])

    # Apply the constraint
    slab.set_constraint(c)
    print(slab)
    if not os.path.exists(numstr):
        os.makedirs(numstr+"/opt")
        os.makedirs(numstr+"/band")
        pass
    slab.write(numstr+"/opt/POSCAR", vasp5=True, direct=True)
    pass
#+end_src

对于其它金属， ASE 也有支持，详细说明请看它的文档[fn::
https://wiki.fysik.dtu.dk/ase/ase/build/build.html]。

** TODO 组内集群折腾实录
